
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>WebRTC c0d3l4b</title>
  <script src="./bower_components/webcomponentsjs/webcomponents-lite.js"></script>
  <link rel="import" href="bower_components/codelab-components/google-codelab-elements.html">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <style is="custom-style">
    body {
      font-family: "Roboto",sans-serif;
      background: var(--google-codelab-background, --paper-grey-300);
    }
  </style>
  
</head>
<body unresolved class="fullbleed">

  <google-codelab title="WebRTC c0d3l4b"
                  environment="web"
                  feedback-link="https://github.com/misi/codelab/issues">
    
      <google-codelab-step label="Introduction" duration="5">
        <p>This codelab is focused on WebRTC Apps.</p>
<h2><strong>What is WebRTC?</strong></h2>
<table>
<tr><td colspan="1" rowspan="1"><p><strong>WebRTC is</strong></p>
<ul>
<li>An open source project</li>
<li>A new protocol framework</li>
<li>Working groups in standardization bodies (IETF, W3C)</li>
<li>A new market </li>
<li>Etc.</li>
</ul>
<p><strong>WebRTC&#39;s Mission is to </strong></p>
<ul>
<li>Enhance the web with  Real Time Communication (RTC) capabilities, and define a simple JS API for web developers. </li>
<li>make the browser capable to act like VC terminals (Audio/Video/Data). </li>
</ul>
</td><td colspan="1" rowspan="1"><h2><img style="max-width: 181.50px" src="img/6f5abad9e3b52099.png"></h2>
</td></tr>
</table>
<h3><strong>WebRTC Official Definitions:</strong></h3>
<ul>
<li>WebRTC: &#34;A framework, protocols and application programming interface that provide real time interactive voice, video and data in web browsers and other applications&#34;</li>
<li>WebRTC is a free, open project that provides browsers and mobile applications with Real-Time Communications (RTC) capabilities via simple APIs. The WebRTC components have been optimized to best serve this purpose.</li>
<li>Mission: To enable rich, high-quality RTC applications to be developed for the browser, mobile platforms, and IoT devices, and allow them all to communicate via a common set of protocols.</li>
</ul>
<h3><strong>The WebRTC Project</strong></h3>
<ul>
<li><strong>Web</strong>: <a href="https://webrtc.org" target="_blank">https://webrtc.org</a></li>
<li><strong>WebRTC Project Logo: </strong><a href="https://webrtc.org/press/" target="_blank">https://webrtc.org/press/</a></li>
</ul>
<p><br>This codelab will walk you through creating your first own WebRTC App, including all the theory needed to understand the JS API and under the hood protocols, and design considerations, as well as all implementation details, to ensure that your app work properly in every network conditions and environment.</p>
<h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>How to design a WebRTC App</li>
<li>How to use the basic WebRTC API-s</li>
<li>How to grab a MediaDevice. e.g. How to grab your WebCam&#39;s VideoStream.</li>
<li>How to set mediaStream Input and Output devices</li>
<li>How to setup a PeerConnection</li>
<li>How to setup PC for proper NAT Traversal</li>
<li>How to use a DataChannel</li>
<li>How to record a MediaStream locally</li>
</ul>
<h2><strong>What you&#39;ll need</strong></h2>
<ul>
<li>A recent version of Chrome and Firefox Browser. <br>(Note, this should work in other browsers as well.)</li>
<li>The CodeLab Samples</li>
<li>A text editor</li>
<li>SSH client</li>
<li>Basic knowledge of HTML, CSS, JavaScript.</li>
</ul>
<aside class="special"><p><strong>Last but not least</strong>: </p>
<p>This c0d3l4b is strongly inspired by Google WebRTC CodeLab!<em> (Special thx to Sam Dutton!)</em></p>
<p><a href="https://codelabs.developers.google.com" target="_blank">https://codelabs.developers.google.com</a> </p>
<p><em>And also many thanks Google for the codelab framework!</em></p>
<ul>
<li><a href="https://github.com/googlecodelabs/codelab-components" target="_blank">https://github.com/googlecodelabs/</a></li>
<li><a href="https://g.co/codelabs/guide" target="_blank">https://g.co/codelabs/guideâ€‹</a></li>
</ul>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Getting set up" duration="10">
        <h2><strong>Setup a web server with TLS support on Your host</strong></h2>
<p>Install on your host a web server with a certificate from <a href="https://letsencrypt.org/" target="_blank">let&#39;s encrypt</a>.</p>
<p>If you use chrome you could also use web-server-for-chrome extension:</p>
<p><a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en" target="_blank"><paper-button class="colored" raised>Install Web Server for Chrome</paper-button></a></p>
<aside class="special"><p><strong>Tip</strong>: We have created pre install VM with certificate and web server. <br>Please test it and login on your VM with your ssh client.</p>
</aside>
<h2><strong>You could Download the Sample Code</strong></h2>
<p>Click the following link to download all the code for this codelab:</p>
<p><a href="https://github.com/misi/codelab/archive/master.zip" target="_blank"><paper-button class="colored" raised><iron-icon icon="file-download"></iron-icon>Download source code</paper-button></a></p>
<p><strong>Or</strong></p>
<pre>git clone https://github.com/misi/codelab.git</pre>
<p>Unpack the zip file in your <code>web server root directory</code>. This will unpack a root folder (<code>codelab</code>), which contains one <code>labN</code> folder for each step of this codelab, along with all of the resources you will need.</p>
<p>The <code>labN</code> folders contain the desired end state of each step of this codelab. They are there for reference. We&#39;ll be doing all our coding work in a directory called <code>work</code>.</p>
<h2><strong>Ready? =&gt; Let&#39;s Start the theory!</strong></h2>
<p>WebRTC is complex and could be hard to understand for a web developer without proper understanding of WebRTC Architecture and technologies working under the hood.</p>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC Design Goals" duration="0">
        <h2><strong>Goals</strong></h2>
<ul>
<li><strong>Easy to use for the end user (</strong>Without Plugins, Without Install, Always up2date client)</li>
<li><strong>Multi platform (</strong>Exotic platforms no more excluded from RTC.<strong>)</strong></li>
<li><strong>Push the envelope</strong>: Low Latency / Jitter,  Advanced congestion avoidance, Adaptive Audio Video encoding and Forward Error Correction (FEC)</li>
<li><strong>Firewall and NAT Traversal</strong> ICE(STUN/TURN)</li>
<li><strong>Focus on Security and Privacy and Identity validation by design</strong>, encrypted Secure End to End communication, ask consent before access a MediaDevice, avoid fingerprinting</li>
<li><strong>Open Source Native Implementation</strong> (for browser vendors and beyond browsers)</li>
<li><strong>Open Standard</strong> (W3C, IETF)</li>
<li><strong>Interwork with any Signaling</strong></li>
<li><strong>Backward compatibility</strong> in WebRTC 1.0  (e.g. SDP and G.711audio codec)</li>
</ul>
<h2><strong>Base components:</strong></h2>
<ul>
<li><strong>GetUserMedia</strong> (GuM): Grab MediaStream from a MediaDevice</li>
<li><strong>PeerConnection</strong> (PC): Establish and Maintain Peer to Peer Connection</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Standardization" duration="5">
        <h2><strong>Codecs</strong></h2>
<h3><strong>Mandator to Implement Audio codec</strong></h3>
<ul>
<li>G711</li>
<li>Opus</li>
</ul>
<h3><strong>Mandatory to Implement Video codecs</strong></h3>
<p>It took a long to build consensus in the IETF RTCWEB workgroup (&#34;Codec war..&#34;)</p>
<ul>
<li>VP8 vs H.264</li>
<li>(VP9 vs H.265)</li>
</ul>
<h4>Alliance for Open Media</h4>
<ul>
<li>AOMedia Video 1 (AV1) development</li>
<li>Amazon, Cisco, Google, Intel, Microsoft, Mozilla, Netflix, etc.</li>
</ul>
<h2><strong>WebRTC 1.0</strong></h2>
<ul>
<li><strong>W3C</strong> WebRTC  - PeerConnection , GuM ++</li>
<li><strong>IETF</strong> rtcweb ++</li>
</ul>
<h2>WebRTC NV</h2>
<ul>
<li>QUIC transport for DataChannel/(Media?)</li>
<li>More ORTC like deep API</li>
<li>No more SDP</li>
<li>More control on ICE Agent</li>
<li>SVC</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="History" duration="5">
        <h2>The begining</h2>
<ul>
<li>2009 - Google Chrome Team Idea</li>
<li>2010 Summer - IETF 98 Informal lunch (Google, Microsoft, Apple, Mozilla, Skype, Ericsson,etc.)</li>
<li>2010 October - RTC Web Workshop <a href="http://rtc-web.alvestrand.com/" target="_blank">http://rtc-web.alvestrand.com/</a></li>
<li>2011 January - Google Global IP Solution (GIPS) acquired.</li>
<li>2011 May - W3C WebRTC WG statarted officialy</li>
<li>2011 June - Googe Anounce WebRTC project(based on GIPS) and chrome integration</li>
<li>2011 Nov - Chrome 23 WebRTC support</li>
</ul>
<h2>Early birds</h2>
<ul>
<li>2013 January - Firefox 20 first WebRTC support (only GuM)</li>
<li>2013 February - Chrome Mozilla first call interoperability</li>
<li>2013 July - Chrome for Android support</li>
<li>2013 September - Firefox for Android support</li>
<li>2013 October - Open H.264 Cisco (Mozilla)</li>
<li>2013 October - Opera 18 Beta WebRTC debut.</li>
</ul>
<h2>Onbording on webRTC train</h2>
<ul>
<li>2014 September - OpenWebRTC (Ericsson)</li>
<li>2014 October - Microsoft Edge ORTC Announcement</li>
<li>2014 November - Consensus on Mandatory to Implement Video Condecs :-)</li>
<li>2015 September - Microsoft Edge ORTC/WebRTC support</li>
<li>2015 November - Mozilla Canvas CaptureStream</li>
<li>2016 January - VP9 Chrome</li>
<li>2016 April - ICE Restart Firefox 48</li>
</ul>
<h2>Nowadays</h2>
<ul>
<li>2017 June - Safari 11 WebRTC Support</li>
<li>2017 October - KITE WebRTC platform test</li>
<li>2017 October - Third Party Audio Codec Support</li>
<li>2017 November - WebRTC PeerConnection CR (W3C)</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Mind the Gap!" duration="0">
        <p>Duration: 5:00</p>
<p><img style="max-width: 624.00px" src="img/bccbe1f1d373bd49.png"></p>
<p>Source: <a href="http://art.fritsahlefeldt.com/photo/2414/Mind-the-gap-with-text-Color-illustration.html" target="_blank">http://art.fritsahlefeldt.com/photo/2414/Mind-the-gap-with-text-Color-illustration.html</a></p>
<h2><strong>Adapter.js</strong></h2>
<p>Standardization is a moving target. Mind the gap between:</p>
<ul>
<li>Standard and Browser Implementations</li>
<li>Between bowser implementations</li>
<li>Application and Standard</li>
</ul>
<p>The adapter.js is a shim to insulate apps from spec changes and prefix differences.</p>
<ul>
<li><a href="https://github.com/webrtc/adapter" target="_blank">https://github.com/webrtc/adapter</a></li>
<li><a href="https://webrtc.org/web-apis/interop" target="_blank">https://webrtc.org/web-apis/interop/</a></li>
</ul>
<h2><strong>Breaking Changes</strong></h2>
<ul>
<li>Firefox adds deprecation warning</li>
<li>Carefully age out, pull down not too soon.</li>
</ul>
<h3><strong>Changes</strong></h3>
<ul>
<li>Async API =&gt; Move from callbacks, forward to Promises</li>
</ul>
<h4>Media Capture Changes: </h4>
<p><strong>MediaDevice selection, detection on changes (discovery)</strong></p>
<ul>
<li><strong>Old</strong>: <code>navigator.getUserMedia</code> is deprecated</li>
<li><strong>New</strong>: <code>navigator.mediaDevices.getUserMedia</code></li>
</ul>
<p><strong>Media source</strong></p>
<ul>
<li><strong>Old</strong>: <code>video.createObjectURL</code> is deprecated</li>
<li><strong>New</strong>: <code>video.srcObject</code></li>
</ul>
<h3><strong>Constraint changed</strong></h3>
<p><strong>Legacy deprecated Constraint</strong></p>
<pre><code>{
  mandatory: {width: {min: 640, max:1920}}, 
  optional [{width: 1280}]
}</code></pre>
<p><strong>New modern Constraint</strong></p>
<pre><code>{width: {min:1024, ideal: 1280, max: 1920}}</code></pre>
<ul>
<li>Chrome constraints are deprecated</li>
<li>&#34;optional&#34; renamed to &#34;advanced&#34;</li>
</ul>
<h3><strong>Stats Changes</strong></h3>
<p><strong>Legacy deprecated Stats</strong></p>
<pre><code>pc.getStats(function(stats){
      Object.keys(stats).forEach(key =&gt;...)
   }
)</code></pre>
<p><strong>New modern Stats (promise)</strong></p>
<pre><code>pc.getStats().then(stats =&gt;stats.forEach(value=&gt;...)</code></pre>
<h3><strong>Streams =&gt; Tracks</strong></h3>
<p>Manipulating (replacing tracks) after added a stream to peerconnection makes confusion, so add tracks instead of streams to peerconnection.</p>
<p><strong>addStream is deprecated</strong></p>
<ul>
<li><strong>Old</strong>: <code>pc.addStream(stream)</code></li>
<li><strong>New</strong>: <code>stream.forEach(track =&gt; pc.addTrack(track,stream))</code></li>
</ul>
<p><strong>getLocalStreams is deprecated</strong></p>
<ul>
<li><strong>Old</strong>: <code>var streams = pc.getLocalStreams();</code></li>
<li><strong>New</strong>: <code>var senders = pc.getSenders();</code></li>
</ul>
<aside class="special"><p><strong>Tip:</strong></p>
<p>For more details see Jan-Ivar&#39;s presentation: <a href="https://www.crowdcast.io/e/webrtcstandards13" target="_blank">https://www.crowdcast.io/e/webrtcstandards13</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC Architecture" duration="5">
        <h3><strong>Protocol Stack</strong></h3>
<p><img style="max-width: 520.00px" src="img/ea08a380495f9f3e.png"></p>
<p>WebRTC native Architecture</p>
<p><img style="max-width: 624.00px" src="img/fcdec68b59f9447d.png"></p>
<p><a href="https://webrtc.org/architecture/" target="_blank">https://webrtc.org/architecture/</a></p>
<h2><strong>WebRTC Trapezoid</strong></h2>
<h3><strong>Direct Peer to Peer Connection</strong></h3>
<p><img style="max-width: 624.00px" src="img/149faeda7a820cf4.png"></p>
<aside class="special"><p><strong>Note</strong>:</p>
<p>Direct Browser to Browser connection is prefered by default to keep the end to end delay low. ICE preferes by default TURN in last resort.</p>
<p>Of course there are other reasonable preferences, like safe connection or short connection establishment time, that may override ICE default behavior and prefer TURN first.</p>
</aside>
<h3><strong>Address and Port-Dependent Mapping &amp; Address and Port-Dependent Filtering (Symmetric) NAT</strong></h3>
<p><img style="max-width: 624.00px" src="img/a090a6dbe2aec127.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="NAT/Firewall traversal &amp; ICE (STUN/TURN)" duration="15">
        <h2><img style="max-width: 624.00px" src="img/a4ab88365707a723.png"></h2>
<h2><strong>TL;DR</strong></h2>
<ul>
<li>STUN is a binary protocol</li>
<li>STUN Discover Client global IP:port</li>
<li>TURN is a STUN protocol extension</li>
<li>TURN is about Allocate a global IP:port and tunnel and Relay traffic</li>
<li>ICE finds the shortest working path between two ICE agents</li>
</ul>
<h2><strong>Multiplexing</strong></h2>
<ul>
<li>RTP/RTCP multiplexing</li>
<li>RTP multiplexing (audio video)</li>
</ul>
<aside class="special"><p><strong>Nice ICE Tutorials</strong>:</p>
<ul>
<li><a href="https://sdstrowes.co.uk/talks/20081031-ice-turn-stun-tutorial.pdf" target="_blank">https://sdstrowes.co.uk/talks/20081031-ice-turn-stun-tutorial.pdf</a></li>
<li><a href="http://www.jdrosen.net/uploads/1/5/0/0/15008848/ice-ietf-tutorial2.pptx" target="_blank">http://www.jdrosen.net/uploads/1/5/0/0/15008848/ice-ietf-tutorial2.pptx</a></li>
</ul>
</aside>
<h2><strong>Congestion Avoidance</strong></h2>
<p><strong>Standardization is in IETF RMCAT</strong></p>
<ul>
<li>Receiver Estimated Maximum Bandwidth (REMB)</li>
<li>Sender Side Bandwidth Estimation</li>
<li>Forward Error Correction (FEC)</li>
</ul>
<p><strong>More Details</strong>:</p>
<ul>
<li><a href="http://www.rtcbits.com/2017/01/bandwidth-estimation-in-webrtc-and-new.html" target="_blank">http://www.rtcbits.com/2017/01/bandwidth-estimation-in-webrtc-and-new.html</a></li>
<li><a href="https://blog.mozilla.org/webrtc/what-is-rmcat-congestion-control" target="_blank">https://blog.mozilla.org/webrtc/what-is-rmcat-congestion-control</a>/</li>
<li><a href="https://public.boxcloud.com/d/1/MgC0Sn2Nrq-7JGAy46x2KYfGBwqTTQUu7hNq-V153kgoiOY1F_w48tsn_bsqvocMmaHon1tjDDe8aGFj0MMMbWjEbRlqvG3-mjE5wUqbxx_XyyDIH8VlGzFOL3FX9wuCaQDfTtfnFDtKBBH49bPPyjh_Vjt_QNpzWFTk2TOmWRtRQsqZ9OGvGP7wHqYhZcqWucrlgZw5eSJD8X9dsOHcDHuVWWL5AXu_pdqjEjjNqk3eiYKgMMvmvvHqxTvKumdpLN244__ibPxgLqZZyvv7zd479-SEJYGugxgTzvqqj8F02rh6N_jhA1ZyWSw5KkoQbdP62zuHlS8Vj74xBP0ZkauTA52Yt5apBjmShjsE6lgKoe3W-eMqgC_iS0oLjasqPfVT6C7fUaXl___jznddbaWWWcPilkyXWjSl5-8PBboFpL-eDnI5WCy4092yCtBzaOBlIco3g1g2gSjv6MWWmwNRbl8JGNmsvTLkaG_KY7uW9KLE617ny_3LEIsLi6srUPgT_UbLHAxn6cY5Voo3AeSsjaFXgHvycA8TB7zNPQ9jx8GlpH4DDu_uDLxKV_BE9PKrqRftURMWXp-cckMqT3-1pgpGLnol7BK_cAQH6pkm7lpGJ-OOD_TrlpxvINE_Z7OEjAPdEHA0ngNmKRCcmRan57wJ96TlLJh5kUjJMdOT7A2tIlAnTCly05khfay_RtWUnqPugv1xq7oTBW_2STeoeOjgOYT8wQpCqVSu4DnlE2pU25yj043oOVLbRhBeetxwD4Co1A10tVsUHEdkmeNBoKkBUaxdHVj_12soIviUEwjFVpsi6cn9L4rvUTADd2yizWc2fVmuibdycVTVejgsemdWh3nH4QPHcoZ-umsxFocgTN0bKxpZwypWY0aodtouH4FCVdt4lxgogbabex9cZSyoYRnluaGRXyJlODYZVk6oP2YAKmQv2ZuE61GqMKB7HA9HcT0wnwFOWLJqXaKzJX8hQsyEi1Do9r7Fbs05Y_6XPyUAiwcyf95nlFEGWuNZYjVdSnq7M_xVzRhZp4iyob_E9W0NXJGijroJNulxLgLw0NZmXPhPEegqYOIEt7C2p5teFblYdHbTmz-A2LoW2tN0SDagO-cB8GN_G4l6iBdiF-rubNkp8OMEduyHj2Z6opFkLOCdxeMPOh2JAD8hbcmWW9dv1688YOswPAHON92H173m47Xd0JIlr9zmT58Cy1RS_pjNVVXVeA../download" target="_blank">TF-WebRTC_5_Congestion_Luca.pdf</a></li>
<li><a href="https://www.callstats.io/2016/11/14/fec-congestion-control/" target="_blank">https://www.callstats.io/2016/11/14/fec-congestion-control/</a></li>
<li><a href="https://www.callstats.io/2017/10/16/acm-multimedia/" target="_blank">https://www.callstats.io/2017/10/16/acm-multimedia/</a></li>
</ul>
<h2><strong>STUN/TURN</strong></h2>
<h3><strong>STUN - Binding:</strong></h3>
<p><img style="max-width: 624.00px" src="img/c73944b647485a86.png"></p>
<h3><strong>TURN - Allocate</strong></h3>
<p><img style="max-width: 624.00px" src="img/59609b44fde7fdad.png"></p>
<h2>ICE</h2>
<h3><strong>Design Goals</strong></h3>
<ul>
<li>High reliability is essential</li>
<li>Minimize the &#34;length&#34; of the path between clients</li>
<li>Negotiate IP protocol version (IPv4/IPV6) and preference</li>
<li>No assumption on: (Network topologies, NAT or Firewall presence, NAT behaviours)</li>
</ul>
<h3><strong>ICE Steps</strong></h3>
<ul>
<li>Discovery and Candidate gathering (Allocation)</li>
<li>Prioritisation</li>
<li>Exchange (SDP)</li>
<li>Connectivity Check (Binding Request + Short Term Credential)</li>
<li>Coordination (Controlling/Controlled, Nomination)</li>
<li>Communication</li>
</ul>
<h3><strong>ICE prioritization</strong></h3>
<pre><code>priority = (2^24)*(type preference)
          +(2^8)*(local preference)
          +(2^0)*(256 - component ID) </code></pre>
<p><strong>priority (32bit)</strong></p>
<ul>
<li><strong>Type preference (8 bit): 0-126 </strong>The RECOMMENDED values are 126 for host candidates, 100 for server reflexive candidates, 110 for peer reflexive candidates, and 0 for relayed candidates.</li>
<li><strong>Local preference(16 bit):</strong> Version(IPv4/IPv6), network interfaces(VPN/LAN)</li>
<li><strong>Component ID (8bit) 256 - component ID</strong></li>
</ul>
<h3><strong>Foundation</strong></h3>
<p>Candidates has the same foundation and are similar when they are of the same type and obtained from the same interface and STUN or TURN server.</p>
<h3><strong>Frozen Algorithm</strong></h3>
<p>The idea is to use the results of a previous check to predict the likelihood of a future one working. </p>
<h2><strong>ICE Agent States</strong></h2>
<p><img style="max-width: 624.00px" src="img/8ad2e7ad2cd572cf.png"></p>
<p>For more details see the ICE tutorials mentioned above.</p>
<h2><strong>Trickle ICE</strong></h2>
<p>Connection establishment time could be long if we need to wait to finish the candidate discovery. </p>
<p>Even worse, in case of any error is occuring during the discovery. Waiting for the timeouts could take long, and could cause an unacceptable very long connection establishment. </p>
<p>The primary idea is to start ICE check as fast as we discover a candidate. The only drawback is that we need to send more signaling messages. WebRTC Application nowadays use mostly Trickle ICE to establish connection.</p>
<p><img style="max-width: 624.00px" src="img/bc12d7ccb7c091cf.png"></p>
<h2><strong>NAT Behavior Discovery (RFC5780)</strong></h2>
<h3><strong>RFC 3489 definitions:</strong></h3>
<ul>
<li>Full Cone</li>
<li>Restricted Cone</li>
<li>Port Restricted Cone</li>
<li>Symmetric</li>
</ul>
<h3><strong>RFC 4787 and RFC 5780 base class definitions:</strong></h3>
<p><strong>Mapping</strong></p>
<ul>
<li>Endpoint Independent Mapping</li>
<li>Address-Dependent Mapping</li>
<li>Address and Port-Dependent Mapping</li>
</ul>
<p><strong>Filtering</strong></p>
<ul>
<li>Endpoint Independent Filtering</li>
<li>Address-Dependent Filtering</li>
<li>Address and Port-Dependent Filtering</li>
</ul>
<p><img style="max-width: 624.00px" src="img/5159f9e65f6a5e50.png"></p>
<aside class="special"><p><strong>Tip</strong>: </p>
<p>See coTURN turnutils_natdiscovery README for options <a href="https://github.com/coturn/coturn/blob/master/README.turnutils" target="_blank">https://github.com/coturn/coturn/blob/master/README.turnutils</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="SDP" duration="0">
        <p>Duration: 10 min</p>
<aside class="special"><p><strong>Tip</strong>: SDP Anatomy on webrtcH4cKS <a href="https://webrtchacks.com/sdp-anatomy" target="_blank">https://webrtchacks.com/sdp-anatomy</a></p>
</aside>
<h3><strong>Plans</strong></h3>
<p><strong>Unified Plan</strong>: </p>
<ul>
<li><a href="https://webrtcglossary.com/unified-plan" target="_blank">https://webrtcglossary.com/unified-plan</a></li>
<li><a href="https://tools.ietf.org/html/draft-roach-mmusic-unified-plan-00" target="_blank">https://tools.ietf.org/html/draft-roach-mmusic-unified-plan-00</a></li>
</ul>
<p><strong>Plan B</strong>: (Obsoleted!)</p>
<ul>
<li><a href="https://webrtcglossary.com/unified-plan" target="_blank">https://webrtcglossary.com/unified-plan</a></li>
<li><a href="https://tools.ietf.org/html/draft-uberti-rtcweb-plan-00" target="_blank">https://tools.ietf.org/html/draft-uberti-rtcweb-plan-00</a></li>
<li>Chrome / Chromium is still working the transition to Unified Plan  <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=465349" target="_blank">https://bugs.chromium.org/p/chromium/issues/detail?id=465349</a></li>
</ul>
<aside class="special"><p><strong>Plan Adapter</strong>: It is very hard to polyfill plan differences, but here  is an example. <a href="https://www.npmjs.com/package/sdp-interop" target="_blank">https://www.npmjs.com/package/sdp-interop</a></p>
</aside>
<h2><strong>Example SDP</strong></h2>
<h3><strong>Offer</strong></h3>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-58.0.2 1392930692610468855 0 IN IP4 0.0.0.0
s=-
t=0 0
a=sendrecv
a=fingerprint:sha-256 97:73:D6:F9:B8:4C:4A:29:3B:E0:B4:3E:E6:37:F6:D0:B7:8A:88:D9:E5:D2:C4:F8:74:66:18:B7:84:18:BB:42
a=group:BUNDLE sdparta_0 sdparta_1
a=ice-options:trickle
a=msid-semantic:WMS *
m=audio 51644 UDP/TLS/RTP/SAVPF 109 9 0 8 101
c=IN IP4 193.224.69.74
a=candidate:0 1 UDP 2122252543 192.0.2.1 53693 typ host
a=candidate:4 1 TCP 2105524479 192.0.2.1 9 typ host tcptype active
a=candidate:0 2 UDP 2122252542 192.0.2.1 40157 typ host
a=candidate:4 2 TCP 2105524478 192.0.2.1 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 51644 typ relay raddr 193.224.69.74 rport 51644
a=candidate:3 2 UDP 92217086 193.224.69.74 64126 typ relay raddr 193.224.69.74 rport 64126
a=sendrecv
a=end-of-candidates
a=extmap:1/sendonly urn:ietf:params:rtp-hdrext:ssrc-audio-level
a=extmap:2 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:109 maxplaybackrate=48000;stereo=1;useinbandfec=1
a=fmtp:101 0-15
a=ice-pwd:957d8d9d754992a1d5a7706d5cb2e1fe
a=ice-ufrag:732f8881
a=mid:sdparta_0
a=msid:{69779578-0a01-46d5-afb8-c1ce8eb8b4f7} {3b93eb2f-9bf4-4955-95d0-5379eeba3e11}
a=rtcp:64126 IN IP4 193.224.69.74
a=rtcp-mux
a=rtpmap:109 opus/48000/2
a=rtpmap:9 G722/8000/1
a=rtpmap:0 PCMU/8000
a=rtpmap:8 PCMA/8000
a=rtpmap:101 telephone-event/8000
a=setup:actpass
a=ssrc:2764815782 cname:{08b8c6e5-8963-4a02-825f-d55ddb7076ba}
m=video 51644 UDP/TLS/RTP/SAVPF 120 121 126 97
c=IN IP4 193.224.69.74
a=candidate:0 1 UDP 2122252543 192.0.2.1 55556 typ host
a=candidate:4 1 TCP 2105524479 192.0.2.1 9 typ host tcptype active
a=candidate:0 2 UDP 2122252542 192.0.2.1 42946 typ host
a=candidate:4 2 TCP 2105524478 192.0.2.1 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 52200 typ relay raddr 193.224.69.74 rport 52200
a=candidate:3 2 UDP 92217086 193.224.69.74 65354 typ relay raddr 193.224.69.74 rport 65354
a=sendrecv
a=extmap:1 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time
a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:126 profile-level-id=42e01f;level-asymmetry-allowed=1;packetization-mode=1
a=fmtp:97 profile-level-id=42e01f;level-asymmetry-allowed=1
a=fmtp:120 max-fs=12288;max-fr=60
a=fmtp:121 max-fs=12288;max-fr=60
a=ice-pwd:957d8d9d754992a1d5a7706d5cb2e1fe
a=ice-ufrag:732f8881
a=mid:sdparta_1
a=msid:{69779578-0a01-46d5-afb8-c1ce8eb8b4f7} {c4e521ab-ac5c-468d-bda4-102fa8c63ad1}
a=rtcp:65354 IN IP4 193.224.69.74
a=rtcp-fb:120 nack
a=rtcp-fb:120 nack pli
a=rtcp-fb:120 ccm fir
a=rtcp-fb:120 goog-remb
a=rtcp-fb:121 nack
a=rtcp-fb:121 nack pli
a=rtcp-fb:121 ccm fir
a=rtcp-fb:121 goog-remb
a=rtcp-fb:126 nack
a=rtcp-fb:126 nack pli
a=rtcp-fb:126 ccm fir
a=rtcp-fb:126 goog-remb
a=rtcp-fb:97 nack
a=rtcp-fb:97 nack pli
a=rtcp-fb:97 ccm fir
a=rtcp-fb:97 goog-remb
a=rtcp-mux
a=rtpmap:120 VP8/90000
a=rtpmap:121 VP9/90000
a=rtpmap:126 H264/90000
a=rtpmap:97 H264/90000
a=setup:actpass
a=ssrc:1307424569 cname:{08b8c6e5-8963-4a02-825f-d55ddb7076ba}</code></pre>
<h3><strong>Answer</strong></h3>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-58.0.2 8465178051030770266 0 IN IP4 0.0.0.0
s=-
t=0 0
a=sendrecv
a=fingerprint:sha-256 F7:8B:D4:93:EC:66:10:17:A7:88:E2:DB:E2:02:D8:A8:0E:78:0C:47:D1:CF:AC:A8:4A:7F:B0:F8:9C:22:54:DD
a=group:BUNDLE sdparta_0 sdparta_1
a=ice-options:trickle
a=msid-semantic:WMS *
m=audio 9 UDP/TLS/RTP/SAVPF 109 101
c=IN IP4 0.0.0.0
a=candidate:0 1 UDP 2122252543 198.51.100.65 39578 typ host
a=candidate:4 1 UDP 2122187007 198.51.100.177 34202 typ host
a=candidate:8 1 TCP 2105524479 198.51.100.65 9 typ host tcptype active
a=candidate:9 1 TCP 2105458943 198.51.100.177 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 55675 typ relay raddr 193.224.69.74 rport 55675
a=sendrecv
a=extmap:2 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:109 maxplaybackrate=48000;stereo=1;useinbandfec=1
a=fmtp:101 0-15
a=ice-pwd:36acccb528a6c8502e42656cc6c7b8cd
a=ice-ufrag:14888916
a=mid:sdparta_0
a=msid:{9cc1f70c-c78b-44b4-86fa-fcd82c530b1e} {4662f9ed-4a45-4f9f-964d-4ffff5535e5f}
a=rtcp-mux
a=rtpmap:109 opus/48000/2
a=rtpmap:101 telephone-event/8000
a=setup:active
a=ssrc:1899896363 cname:{0cc05c74-02a9-4474-9885-9ea7674b8299}
m=video 9 UDP/TLS/RTP/SAVPF 120
c=IN IP4 0.0.0.0
a=sendrecv
a=extmap:1 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time
a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:120 max-fs=12288;max-fr=60
a=ice-pwd:36acccb528a6c8502e42656cc6c7b8cd
a=ice-ufrag:14888916
a=mid:sdparta_1
a=msid:{9cc1f70c-c78b-44b4-86fa-fcd82c530b1e} {425480c1-460a-4b92-8b43-59cc59062d0d}
a=rtcp-fb:120 nack
a=rtcp-fb:120 nack pli
a=rtcp-fb:120 ccm fir
a=rtcp-fb:120 goog-remb
a=rtcp-mux
a=rtpmap:120 VP8/90000
a=setup:active
a=ssrc:377924797 cname:{0cc05c74-02a9-4474-9885-9ea7674b8299}</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Offer Answer" duration="5">
        <h2><strong>WebRTC Offer/Answer Model</strong></h2>
<p><img style="max-width: 624.00px" src="img/4f1ff8d0dc38445c.png"></p>
<h2><strong>PeerConnection States</strong></h2>
<p><img style="max-width: 600.00px" src="img/eddf66e8239393c2.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC Security Architecture" duration="5">
        <h2><strong>GetUserMedia</strong></h2>
<ul>
<li>Secure User Interface opt-in (e.g. Camera, audio access)</li>
<li>User can allow/deny audio video source usage</li>
</ul>
<aside class="special"><p><strong>Tip!</strong> See EKR IETF presentation for detaied information: <a href="http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf" target="_blank">http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf</a></p>
</aside>
<h2>Offer Answer <code>without</code><strong> Identity Check</strong></h2>
<p><img style="max-width: 624.00px" src="img/31562214b7e28759.png"></p>
<p>Source: <a href="https://hikingartist.com/2012/01/03/cat-and-dog-online-2-0/" target="_blank">https://hikingartist.com/2012/01/03/cat-and-dog-online-2-0/</a></p>
<h2>Offer Answer <code>with</code><strong> Identity Check</strong></h2>
<p>The trust base is the Browser.</p>
<pre>             +----------------+    Unspecified    +----------------+
             |                |      protocol     |                |
             |    Signaling   |&lt;-----------------&gt;|    Signaling   |
             |    Server      |  (SIP, XMPP, ...) |    Server      |
             |                |                   |                |
             +----------------+                   +----------------+
                      ^                                   ^
                      |                                   |
                HTTPS |                                   | HTTPS
                      |                                   |
                      |                                   |
                      v                                   v
                   JS API                               JS API
             +-----------+                             +-----------+
             |           |             Media           |           |
       Alice |  Browser  |&lt;---------------------------&gt;|  Browser  | Bob
             |           |           DTLS+SRTP         |           |
             +-----------+                             +-----------+
                   ^      ^--+                      +--^     ^
                   |         |                      |        |
                   v         |                      |        v
             +-----------+   |                      |  +-----------+
             |           |&lt;-------------------------+  |           |
             |   IdP1    |   |                         |    IdP2   |
             |           |   +------------------------&gt;|           |
             +-----------+                             +-----------+
                   A federated call with IdP-based identity</pre>
<p>The following two slides are from EKR IETF Presentation mentioned above</p>
<h3><strong>Offer + Identity</strong></h3>
<p><img style="max-width: 624.00px" src="img/76a473e62e8295bc.png"></p>
<h3><strong>Answer + Identity</strong></h3>
<p><img style="max-width: 624.00px" src="img/7d1f3adde43daac0.png"></p>
<h2><strong>Media/Data Encryption is mandatory: SRTP / DTLS</strong></h2>
<ul>
<li>DTLS-SRTP: DTLS and Certificate based key .</li>
<li>SDES-SRTP &#34;MUST NOT implement&#34; according IETF 87</li>
</ul>
<aside class="warning"><p><strong>Important</strong>:  SDES-SRTP is obsoleted, mainly because to avoid any surveillance possibility. This was a design decision, and it could add interop issues with legacy systems!</p>
</aside>
<aside class="special"><p><strong>Note: Identity is a must!</strong> We don&#39;t trust fully anymore in the signaling provider. Earlier, in SDES-SRTP case we have trusted in signaling service provider, that it authenticates the parties in the communication in some form. </p>
<p><em>Be aware that WebRTC designed to use E2E encryption, and without Identity validation security is not complete and leaky(!), this way it is extremely important to validate the Peers Identity.</em></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Multipoint (SFU/MCU, Media Server)" duration="5">
        <h2><strong>Some examples from open source space:</strong></h2>
<ul>
<li><a href="https://mediasoup.org/" target="_blank">https://mediasoup.org</a></li>
<li><a href="https://www.kurento.org/" target="_blank">https://www.kurento.org</a></li>
<li><a href="https://janus.conf.meetecho.com/" target="_blank">https://janus.conf.meetecho.com</a></li>
<li><a href="https://jitsi.org/" target="_blank">https://jitsi.org</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Screensharing" duration="5">
        <h2><strong>Chrome Screen Share extension:</strong></h2>
<h3><strong>inline install</strong></h3>
<ul>
<li><a href="https://developer.chrome.com/webstore/inline_installation" target="_blank">https://developer.chrome.com/webstore/inline_installation</a></li>
</ul>
<h2><strong>Standard</strong></h2>
<ul>
<li><a href="https://www.w3.org/TR/screen-capture/" target="_blank">https://www.w3.org/TR/screen-capture/</a></li>
</ul>
<p><strong>Mozilla</strong></p>
<ul>
<li><a href="https://blog.mozilla.org/webrtc/share-browser-windows-entire-screen-sites-trust/" target="_blank">https://blog.mozilla.org/webrtc/share-browser-windows-entire-screen-sites-trust/</a></li>
<li><a href="https://wiki.mozilla.org/Screensharing" target="_blank">https://wiki.mozilla.org/Screensharing</a></li>
</ul>
<pre><code>mediaConstraints = {
    video: {
        mediaSource: &#34;screen&#34;
    },
};</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Summary of the Theory" duration="5">
        <p><img style="max-width: 624.00px" src="img/de4ee6652313dd7f.png"></p>
<p>Source: <a href="http://art.fritsahlefeldt.com/photo/2045/Goal-is-closer-than-you-think-Color-illustration.html" target="_blank">http://art.fritsahlefeldt.com/photo/2045/Goal-is-closer-than-you-think-Color-illustration.html</a></p>
<h2><strong>WebRTC 1.0 is stable to build reliable service on it.</strong></h2>
<ul>
<li>Strong and wide community</li>
<li>Fast New market</li>
<li>3,5-4 Billion of potential Browsers</li>
<li>More than 1300+ Vendor and Project based on WebRTC</li>
<li>Wide support in browsers: Chrome,Firefox, Opera, Edge, Safari, etc.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 1: GetuserMedia (GuM)" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Get a MediaStream from your WebCam (promise)</li>
<li>MediaStream and MediaStreamTrack differences</li>
<li>How browser asks for consent to access (Web)Camera</li>
<li>Manipulate the video with CSS</li>
</ul>
<h2><strong>Lab1</strong></h2>
<p>You could find this simple sample code in <code>Lab1</code> directory</p>
<h2><strong>HTML Skeleton with an autoplay Video tag </strong></h2>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&#34;utf-8&#34;&gt;
    &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1&#34;&gt;

    &lt;title&gt;WebRTC CodeLab&lt;/title&gt;

    &lt;link rel=&#34;stylesheet&#34; href=&#34;css/main.css&#34; /&gt;
    &lt;link rel=&#34;icon&#34; href=&#34;img/favicon-flask.ico&#34; type=&#34;image/x-icon&#34;&gt;
    &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/webrtc-adapter/6.1.0/adapter.js&#34; defer&gt;&lt;/script&gt;
    &lt;script src=&#34;js/main.js&#34; defer&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;WebRTC CodeLab&lt;/h1&gt;
    &lt;video autoplay&gt;&lt;/video&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<h2><strong>JavaScript</strong></h2>
<p><strong>See</strong>: js/<strong>main.js</strong></p>
<pre><code>// Strict mode changes previously accepted &#34;bad syntax&#34; into real errors.
&#39;use strict&#39;;

const mediaStreamConstraints = {
  video: true,
};

var myStream;

navigator.mediaDevices.getUserMedia(mediaStreamConstraints)
.then(function(mediaStream) {
   /* use the stream */
   myStream=mediaStream;
   var video = document.querySelector(&#39;video&#39;);
   video.srcObject = mediaStream;
})
.catch(function(err) {
   /* handle the error */
  console.error(err);
});</code></pre>
<h2><strong>Manipulate with css</strong></h2>
<p><strong>main.css</strong></p>
<pre><code>video {
    filter:saturate(8) opacity(70%);
}</code></pre>
<aside class="special"><p><strong>Tip!</strong> Filter: <a href="https://www.w3schools.com/cssref/css3_pr_filter.asp" target="_blank">https://www.w3schools.com/cssref/css3_pr_filter.asp</a></p>
</aside>
<h2><strong>Bonus exercises:</strong></h2>
<ul>
<li>Try to use instead of <code>&lt;video autoplay&gt;</code>  in index.html a Java Script in main.js <code>video.onloadedmetadata= (e) =&gt; {e.target.play();}</code></li>
<li>Try out on browser JS dev console:  <code>myStream.getVideoTracks()</code> <code>myStream.getAudioTracks() myStream.getTracks()[0]</code></li>
<li>Try to stop track <code>myStream.getTracks()[0].stop</code></li>
<li>Try out to add audio to constraint <code>const mediaStreamConstraints = {audio:true,  video: true};</code></li>
<li>Get Video width: <code>document.querySelector(&#39;video&#39;).videoWidth</code></li>
<li>Set video <code>width</code> and <code>max-width</code></li>
</ul>
<aside class="special"><p><strong>Note</strong>: </p>
<ul>
<li>MediaStream is synchronized group of MediaStreamTracks. </li>
<li>Even a single MediaStreamTrack can represent multi-channel content, such as stereo or 5.1 audio or stereoscopic video!</li>
<li>If you don&#39;t use autoplay or similar function to start playing the video, then you will see only one still picture.</li>
<li>Make sure your video element doesn&#39;t overflow its container. Add width and max-width to set a preferred size and a maximum size for the video. (The browser will calculate the height automatically.)</li>
</ul>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 2: GuM Constraints" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Find out the supported media constraints</li>
<li>Constraint sets Basic/Required and Advanced</li>
<li>Media Constraints  values: difference between <code>min</code>, <code>max</code>, <code>exact</code>, and <code>ideal</code></li>
<li>Rejected promises (e.g. with <code>OverconstrainedError)</code></li>
</ul>
<h2><strong>Lab2</strong></h2>
<p>You could find the completed Lab in <code>Lab2</code> directory. Play with the constraints (that are supported by browser) and try to add low and high values.</p>
<p>Check the lab JS code and try to modify it, and experience how video change according the constraint change. Start playing with the width and height.</p>
<h2><strong>Supported Constraints</strong></h2>
<p>Get the supported constraints list, that the browser supports.</p>
<pre><code>var supportedConstraints = navigator.mediaDevices.getSupportedConstraints();</code></pre>
<h2><strong>Constraints</strong></h2>
<h3><strong>Basic/Required, Advanced Constraint list</strong></h3>
<ul>
<li><strong>Basic/Required </strong>is a ConstraintSet that the Browser <em>MUST</em> to restrict the settings of the corresponding constrainable properties to the specified values or ranges of values.</li>
<li><strong>Advanced</strong>: is the list of ConstraintSets that the Browser <em>MUST</em> attempt to satisfy, in order, skipping only those that cannot be satisfied. The order of these ConstraintSets is significant. The browser <em>MUST</em> try to satisfy them in the order that is specified.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>var constraints =
  {
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    advanced: [
      {width: 1920, height: 1280},
      {aspectRatio: 1.3333333333}
    ]
  };</code></pre>
<p><strong>In this example above, the browser </strong></p>
<ul>
<li>prefers if possible prefers 1920x1280 </li>
<li>if it is not possible then if possible then it preferes the ascpectRatio  4/3</li>
<li>But the Basic/Required constraints MUST be satisfied in all cases (width minimum 640,  and height 480, with &#34;gravity&#34; to ideal  width 1280 and ideal height 720).</li>
</ul>
<h3><strong>Constraints Values</strong></h3>
<ul>
<li><strong>Exact</strong>: The exact match of the value </li>
<li><strong>Min</strong>/<strong>Max</strong>: Specify a Range lower or higher barrier value</li>
<li><strong>Ideal</strong>: Ideal/prefered value, the browser tries to satisfy with some gravity to this value</li>
</ul>
<aside class="special"><p><strong>Note</strong>: Bare values are treated as <em>Exact</em> values.</p>
</aside>
<p><strong>Exact Ideal example:</strong></p>
<pre><code>var constraints = {
  video: {
    width: { exact: 640},
    height: { ideal: 480}
  }
}</code></pre>
<h3><strong>Further examples</strong></h3>
<p><strong>Framerate</strong></p>
<pre><code>var constraints = { 
  video: {
    frameRate: { 
      ideal: 10, 
      max: 15 
    } 
  }
};</code></pre>
<p><strong>Facing mode</strong></p>
<pre><code>// &#34;user&#34; / &#34;environment&#34; ( / &#34;left&#34; / &#34;right&#34; )
var constraints = {
  video: { 
    facingMode: &#34;user&#34;
  }
};</code></pre>
<h3><strong>OverconstrainedError</strong></h3>
<p>If browser could not satisfy the constraints then promise is rejected with an Overconstrained error. This error object contains the reason.</p>
<p>E.g. Try to add to your constraint a width value that your WebCam is not supporting and see the results on your browser&#39;s developer console log.</p>
<aside class="special"><p><strong>For more detailed definitions and examples</strong>: see the standard <a href="https://w3c.github.io/mediacapture-main" target="_blank">https://w3c.github.io/mediacapture-main</a></p>
</aside>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Define an Constraint with advance constraintset with 1280x720 and 640x480</li>
<li>See a video track Settings/Constraints/Capabilities</li>
</ul>
<pre><code>track=document.querySelector(&#39;video&#39;).srcObject.getTracks()[0];
track.getConstraints();
track.getCapabilities();
track.getSettings();</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 3: GuM I/O Select" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Discovery available MediaDevices</li>
<li>Select Input Audio/Video Device</li>
<li>Select Output Audio Device</li>
</ul>
<h2><strong>Lab3</strong></h2>
<p>You could find the completed Lab in <code>Lab3</code> directory.</p>
<p>Select another input/output from the dropdown list to start media capture. </p>
<aside class="special"><p><strong>Tip</strong>: Try Lab3 on your <strong>mobile</strong> where multiple webcam (front/back) is available.</p>
</aside>
<h3><strong>EnumarateDevices </strong></h3>
<p>Enumarate all Media Devices and add as options to three  dropdown select input </p>
<ul>
<li>Input Audio </li>
<li>Input Video</li>
<li>Output Audio</li>
</ul>
<pre><code>navigator.mediaDevices.enumerateDevices()
  .then(function (devices){
    console.log(devices);
    devices.forEach(function(deviceInfo) {
      var option = document.createElement(&#39;option&#39;);
      option.value = deviceInfo.deviceId;
      if (deviceInfo.kind === &#39;audioinput&#39;) {
        option.text = deviceInfo.label ||
          &#39;Microphone &#39; + (audioInputSelect.length + 1);
        audioInputSelect.appendChild(option);
      } else if (deviceInfo.kind === &#39;audiooutput&#39;) {
        option.text = deviceInfo.label || &#39;Speaker &#39; +
          (audioOutputSelect.length + 1);
        audioOutputSelect.appendChild(option);
      } else if (deviceInfo.kind === &#39;videoinput&#39;) {
        option.text = deviceInfo.label || &#39;Camera &#39; +
          (videoInputSelect.length + 1);
        videoInputSelect.appendChild(option);
      }

    });
  })
  .catch(errorCallback);</code></pre>
<aside class="special"><p><strong>Note</strong>: To avoid any fingerprinting, the browser will not reveal all detailed information of the detected mediadevices until user not give consent to access a MediaDevice. Instead of WebCam name only Id&#39;s will be presented. (To avoid any mislead, if you test this feature don&#39;t use it parallel with persistent consent.)</p>
</aside>
<h3><strong>Select Audio Output</strong></h3>
<aside class="special"><p><strong>Note</strong>: </p>
<p>Audio Output is not part of the main media capture and stream api. It is defined in a separated specification: <a href="https://www.w3.org/TR/audio-output/" target="_blank">https://www.w3.org/TR/audio-output/</a></p>
</aside>
<p>Set output with function <code>setSinkID(mediaDeviceID)</code></p>
<pre><code>function outputSelected(){
  var audioOutputId = audioOutputSelect.value;
  video.setSinkId(audioOutputId);
};</code></pre>
<h3><strong>Select Audio/Video Input</strong></h3>
<p>We adjust the MediaConstraint, and set the <code>deviceId</code> as constraint to select the proper input device.</p>
<pre><code>function inputSelected(){
  if (window.mediaStream){
    let tracks = window.mediaStream.getTracks();

    tracks.forEach(function(track) {
      track.stop();
    });
  };
  var audioInputId = audioInputSelect.value;
  var videoInputId = videoInputSelect.value;
  var mediaStreamConstraints = {
    audio: { deviceId: audioInputId ? {exact: audioInputId } : undefined },
    video: { deviceId: videoInputId ? {exact: videoInputId } : undefined }
  };</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 4: GuM Record" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Discovery available MediaDevices</li>
<li>Select Input Audio/Video Device</li>
<li>Select Output Audio Device</li>
</ul>
<h2><strong>Lab4</strong></h2>
<p>You could find the completed Lab in <code>Lab4</code> directory.</p>
<p>It this lab there are 4 buttons and one dropdown select element.</p>
<ol type="1" start="1">
<li>Use &#34;GetuserMedia&#34; button to start capturing your webCam MediaStream localStream (give your consent to access webcam in the pop-up)</li>
<li>Select from the dropdown the format you prefer for the recording. (Only the supported formats will be listed in this select.)</li>
<li>Use the &#34;Start Recording&#34; button and record your video message :-).</li>
<li>&#34;Stop Recording&#34;</li>
<li>Start &#34;Replay&#34; in another video element, and also add a Link where the recorded file could be downloaded.</li>
</ol>
<h2>MediaStream <strong>Recording API</strong></h2>
<aside class="special"><p><strong>Note</strong>: </p>
<p>MediaRecording is not part of the main media capture and sream api. It is defined in a separated specification: <a href="https://www.w3.org/TR/mediastream-recording/" target="_blank">https://www.w3.org/TR/mediastream-recording/</a></p>
</aside>
<h3><strong>Supported media recording formats</strong></h3>
<p>Create a dropdown list with the supported encoding format.</p>
<pre><code>var types = [&#34;video/webm\;codecs=vp9&#34;,
             &#34;video/webm\;codecs=vp8&#34;,
             &#34;video/webm\;codecs=daala&#34;,
             &#34;video/webm\;codecs=h264&#34;];

for (var i in types) {
  if (MediaRecorder.isTypeSupported(types[i])){
    console.log(&#34;Yes, \&#34;&#34;+types[i] + &#34;\&#34; is probably supported..&#34;);
    var option = document.createElement(&#39;option&#39;);
    option.value = option.text = types[i];
    formatSelect.appendChild(option);
  } else {
    console.log(&#34;Unfortunately \&#34;&#34;+types[i] + &#34;\&#34; not yet supported. :(&#34;);
  };
};</code></pre>
<h3><strong>Start/Stop Recording</strong></h3>
<p>Construnct the <code>MediaRecoderOption</code>. We use in our example only the mimeType based on the selected encoding format.</p>
<h4><strong>MediaRecorderOptions</strong></h4>
<ul>
<li><strong>mimeType</strong>: The mime type you want to use as the recording container for the new MediaRecorder. The container and codec format(s) <a href="https://www.w3.org/TR/mediastream-recording/#biblio-rfc2046" target="_blank">[RFC2046]</a> for the recording, which may include any parameters that are defined for the format.</li>
<li><strong>audioBitsPerSecond</strong>: Aggregate target bits per second for encoding of the Audio track(s), if any.</li>
<li><strong>videoBitsPerSecond</strong>: Aggregate target bits per second for encoding of the Video track(s), if any.</li>
<li><strong>bitsPerSecond</strong>: Aggregate target bits per second for encoding of all Video and Audio Track(s) present</li>
</ul>
<p>After local MediaStream is already captured, we create a MediaRecorderObject and stop with <code>Stop()</code> at the end.</p>
<pre><code>var localStream;
var mediaRecorder;
var chunks = [];

//localStream set by getUserMedia

function record() {
  formatSelect.disabled=true;
  recordButton.disabled=true;
  var mediaRecorderOptions={};
  mediaRecorderOptions.mimeType = formatSelect.value;
  try {
    mediaRecorder = new MediaRecorder(localStream, mediaRecorderOptions);
  } catch (e) {
    console.error(&#34;Error during mediarecorder creation using format(&#34; + format + &#34;): &#34; + e);
    alert(&#34;Error during mediarecorder creation using format(&#34; + format + &#34;)&#34;);
  }
  mediaRecorder.ondataavailable = dataAvailable;
  mediaRecorder.start(25); // collect 25ms of data
  stopButton.disabled=false;
};

function dataAvailable(e){
  chunks.push(e.data);
};

function stop() {
  stopButton.disabled = true;
  mediaRecorder.stop();
  replayButton.disabled = false;
};</code></pre>
<h3><strong>Replay and Download</strong></h3>
<ol type="1" start="1">
<li>We create from the recorded 25sec recorded chunks a Blob object.</li>
<li>Get with the URL createObjectURL</li>
<li>Set this URL as the source of <code>video</code> replay element.</li>
<li>Create a link with the same URL an element and add to the document.</li>
</ol>
<pre><code>function replay() {
  vod.controls = true;
  var buffer = new Blob(chunks, {type: &#39;video/webm&#39;});
  var recordingUrl = window.URL.createObjectURL(buffer);
  vod.src = recordingUrl;
  //Add download link
  var a = document.createElement(&#39;a&#39;);
  var linkText = document.createTextNode(&#34;!!! Download Recording !!!&#34;);
  a.appendChild(linkText);
  a.href = recordingUrl;
  a.title = &#34;!!! Download Recording !!!&#34;
  a.download = &#39;recorded.webm&#39;;
  document.querySelector(&#39;#download&#39;).appendChild(a);
};</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Set in recorder options the Audio/Video or aggregated bit rate. </li>
<li>Check MediaRecorder Pause() and Resume() functions</li>
<li>Modify the media constraints as we learned in previous.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 5: GuM &#43; PC state" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Grab media (consent to access WebCam)</li>
<li>Setup a PeerConnection</li>
<li>Add MediaStreamTrack to the established connection</li>
<li>Add STUN/TURN server and iceTransportPolicy</li>
<li>Setup RTP/RTCP and bundle policy</li>
</ul>
<h2><strong>Lab5</strong></h2>
<p>You could find the completed Lab in <code>Lab5</code> directory.</p>
<p>In this lab we will emulate a Peer to Peer call between two parties in one browser, and this way 2 <code>PeerConnection</code> object will be created pc1 and pc2.</p>
<p>You see 3 buttons &#34;GrabMedia&#34;, &#34;Call&#34;, &#34;Hangup&#34;</p>
<ol type="1" start="1">
<li>Grab your local WebCam mediastream with &#34;GrabMedia&#34;</li>
<li>Establish a peerconnection with the &#34;Call&#34; button</li>
<li>And finally &#34;Hangup&#34; the call.</li>
</ol>
<p><strong>States and SDP</strong>:</p>
<p>See PeerConnection and ICE States and transitions and the offer/answer SDPs on Browser Developer Console (F12)</p>
<aside class="special"><p><strong>Tip!</strong>: Check during a call the browser&#39;s under the hood webrtc pages.</p>
<ul>
<li><strong>Chrome</strong> - chrome://webrtc-internals</li>
<li><strong>Firefox</strong> - about:webrtc</li>
</ul>
</aside>
<h3><strong>Call</strong></h3>
<p>Notice:</p>
<ul>
<li><strong>RTCConfiguration.iceServers</strong>: set your STUN and TURN servers</li>
<li><strong>We use Trickle ICE</strong>: We don&#39;t wait for detection of local candidates but send candidates as soon as they have been discovered.</li>
<li>We <strong>add tracks</strong> from localStream to PeerConnection pc1<br><code>localStream.getTracks().forEach(track =&gt; {pc1.addTrack(track, localStream);});</code></li>
<li>We receive media on PeerConnection pc2 when an <strong>ontrack</strong> (pc2.ontrack<strong>)</strong> event fired. Remote stream is: <code>event.streams[0];</code></li>
</ul>
<pre><code>function call(){
  console.log(&#39;Call Start&#39;);

  callButton.disabled = true;

  var videoTracks = localStream.getVideoTracks();
  var audioTracks = localStream.getAudioTracks();
  if (audioTracks.length &gt; 0) {
    console.log(&#39;Actual Audio device: &#39; + audioTracks[0].label);
  }

  if (videoTracks.length &gt; 0) {
    console.log(&#39;Actual Video device: &#39; + videoTracks[0].label);
  }
  pc1 = new RTCPeerConnection(rtcConfig);
  pc2 = new RTCPeerConnection(rtcConfig);
  console.log(&#39;create peer connection objects&#39;);


  // signaling state
  var signalingStateLog1 = pc1.signalingState;
  var signalingStateLog2 = pc2.signalingState;

  pc1.onsignalingstatechange = function() {
    if (pc1) {
      signalingStateLog1 += &#34; -&gt; &#34; + pc1.signalingState;
      console.log(&#39;PC1 Sinaling: &#39; + signalingStateLog1);
    };
  };

  pc2.onsignalingstatechange = function() {
    if (pc2) {
      signalingStateLog2 += &#34; -&gt; &#34; + pc2.signalingState;
      console.log(&#39;PC2 Sinaling: &#39; + signalingStateLog2);
    };
  };


  // ice state
  var iceConnectionStateLog1 = pc1.iceConnectionState;
  var iceConnectionStateLog2 = pc2.iceConnectionState;

  pc1.oniceconnectionstatechange = function() {
    if (pc1) {
      iceConnectionStateLog1 += &#34; -&gt; &#34; + pc1.iceConnectionState
      console.log(&#39;PC1 ICE: &#39;+ iceConnectionStateLog1);
    };
  };

  pc2.oniceconnectionstatechange = function() {
    if (pc2) {
      iceConnectionStateLog2 += &#34; -&gt; &#34; + pc2.iceConnectionState
      console.log(&#39;PC2 ICE: &#39;+ iceConnectionStateLog2);
    };
  };


  pc1.onicecandidate = function (event){
     pc2.addIceCandidate(event.candidate);
     if(event.candidate) console.log(&#39;pc1 ICE Candidate: &#39;+event.candidate.candidate);
  }

  pc2.onicecandidate = function (event){
     pc1.addIceCandidate(event.candidate);
     if(event.candidate) console.log(&#39;pc2 ICE Candidate: &#39;+event.candidate.candidate);
  }


  pc2.ontrack = function(event) {
    remoteVideo.srcObject = event.streams[0];
    remoteVideo.onloadedmetadata = function(e) {
      remoteVideo.play();
    };
    hangupButton.disabled = false;
  }
  pc2.onnegotiationneeded = () =&gt; {
    try {
      console.log(&#34;pc2&#34;);
    } catch (err) {
      console.error(err);
    }
  };

  // add mediastream
  localStream.getTracks().forEach(track =&gt; {pc1.addTrack(track, localStream);});


  var offerOptions = {
    offerToReceiveAudio: 1,
    offerToReceiveVideo: 1
  };

 // init call
 pc1.createOffer(offerOptions).then( offer =&gt; {
   pc1.setLocalDescription(offer);
   pc2.setRemoteDescription(offer);
   console.log(&#39;Offer: &#39;+offer.sdp);
   pc2.createAnswer().then( answer =&gt; {
     pc2.setLocalDescription(answer);
     pc1.setRemoteDescription(answer);
     console.log(&#39;Answer: &#39;+answer.sdp);
   });
 });
}</code></pre>
<h3><strong>Offer-Answer</strong></h3>
<p><img style="max-width: 624.00px" src="img/4f1ff8d0dc38445c.png"></p>
<h3><strong>Hangup</strong></h3>
<p>Close PeerConnection and stop Tracks</p>
<pre><code>function hangup(){
  pc1.close();
  pc2.close();
  localStream.getTracks().forEach(track =&gt; { track.stop();});
  grabButton.disabled = false;
  hangupButton.disabled = true;
}</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Use media constraints</li>
<li>Use STUN/TURN server: <code>var rtcConfig={iceServers: [{urls: &#39;stun:ltc.turn.geant.org&#39;}]}</code></li>
<li>Change Rtcconfig and set RTCIceTransportPolicy=&#34;Relay&#34;</li>
<li>Change Rtcconfig and set  RTCRtcpMuxPolicy=&#34;max-compat&#34;</li>
<li>Set in your Firefox browser a STUN/TURN Server<br><strong>about:config </strong></li>
</ul>
<pre><code>media.peerconnection.use_document_iceservers = false
media.peerconnection.default_iceservers= [{urls: &#34;stun:ltc.turn.geant.org&#34;}]</code></pre>
<aside class="special"><p><strong>See more:</strong> about FireFox privacy options: <a href="https://wiki.mozilla.org/Media/WebRTC/Privacy" target="_blank">https://wiki.mozilla.org/Media/WebRTC/Privacy</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 6: PC DataChannel Chat" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li><strong>No consent required</strong> for datachannel establishment (<strong>!</strong>)</li>
<li>Setup a PeerConnection with DataChannel</li>
</ul>
<h2><strong>Lab6</strong></h2>
<p>You could find the completed Lab in <code>Lab6</code> directory. <br></p>
<p>In this lab create a simple Peer to Peer chat application using DataChannel (DC). The same way as in previous Lab we establish a PeerConnection between the two parties in one browser. We have 2 <code>PeerConnection</code> object, pc1 and pc2. We name in this sample the two parties Alice (A) and Bob (B). The chat app is very simple, You will find for each participant one read-only text area for chat log, and an input text box where you could type your message.</p>
<aside class="special"><p><strong>Tip!</strong>: Check during a call the browser&#39;s under the hood webrtc pages.</p>
<ul>
<li><strong>Chrome</strong> - chrome://webrtc-internals</li>
<li><strong>Firefox</strong> - about:webrtc</li>
</ul>
</aside>
<h3><strong>DataChannel (DC)</strong></h3>
<ul>
<li>We Init the DC with <code>pc1.createDataChanel()</code></li>
<li>After establishment of DC on pc2 side <code>pc.ondatachannel</code> event is triggered. (We add pc2.onmessage event handler)</li>
<li>We add pc1.onmessage event handler</li>
<li>If we press &#34;enter&#34; (keyCode===13) then we send input value with <code>dc.send(msg);</code></li>
</ul>
<pre><code>//DataChannel
var dc1;
var dc2;

/* (Un)Ordered / (Un)Reliable etc.
 * odrderd: If ordered set to false, data is allowed to be delivered out of order.
 * maxRetransmits: Limits the number of times a channel will retransmit data if not successfully delivered.
 * maxPacketLifeTime: Limits the time (in milliseconds) during which the channel will transmit or retransmit data if not acknowledged.
 * priority: very-low to high  See: https://www.w3.org/TR/webrtc/#dom-rtcprioritytype
 * binaryType: &#34;blob&#34; / &#34;arraybuffer&#34;
 */
const dcInitOptions = {
        ordered: true,
        maxRetransmits: 65535,
        //maxPacketLifeTime: 65535,
        priority: &#34;low&#34;,
        binaryType: &#34;blob&#34;,
};

dc1 = pc1.createDataChannel(&#34;chat&#34;,dcInitOptions);


dc1.onmessage = function(e) {
  log1.value += e.data;
};

pc2.ondatachannel = function(e){
  dc2=e.channel;
  dc2.onmessage = function(e) {
    log2.value += e.data;
  }

};

input1.onkeypress = function (e){
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Alice: &#34;+input1.value+&#34;\n&#34;;
    log1.value += msg;
    dc1.send(msg);
    input1.value=&#34;&#34;;
  }
};

input2.onkeypress = function (e){
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Bob: &#34;+input2.value+&#34;\n&#34;;
    log2.value += msg;
    dc2.send(msg);
    input2.value=&#34;&#34;;
  }
};</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Examine dc1.readystate to make input1 readonly until dc is established</li>
<li>See dcInitOptions for (un)reliable and  (un)ordered transmission etc.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 7: Nodejs Signaling Server (socket.io) Chat" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Setup a node websocket server (What maybe later you could use as Signaling server)</li>
<li>Send and Receive Data on WebSocket</li>
</ul>
<h2><strong>Lab7</strong></h2>
<p>You could find the completed Lab in <code>Lab7</code> directory.  In this lab we reuse the previous lab  simple chat application interface, but replacing the engine under the hood to socket.io. </p>
<pre>cd lab7</pre>
<h3><strong>Copy your key/cert</strong></h3>
<p>Copy <code>cert.pem</code> and <code>prikey.pem</code></p>
<aside class="special"><p><strong>Tip</strong>:If you use vm and use let&#39;s encrypt cert then use ../utils/certcopy.sh</p>
</aside>
<p><code>See:</code><strong><code> package.json</code></strong><code> and see the two dependencies</code></p>
<pre><code>&#34;dependencies&#34;: {
  &#34;https&#34;: &#34;^1.0.0&#34;,
  &#34;socket.io&#34;: &#34;^2.0.4&#34;
}</code></pre>
<p>As alternative of <code>npm install</code> we use <code>yarn install</code> or as shortcut just simple:</p>
<p>yarn</p>
<h3>s<strong>erver.js</strong></h3>
<p>After socket.io client initiates a connection to the server, and sends a room message with room name, the server will join this client to the chosen room. Any further messages are broadcasted to all client in the room (except the sender).</p>
<p>&#39;use strict&#39;;</p>
<p>const https = require(&#39;https&#39;);</p>
<p>const fs = require(&#39;fs&#39;);</p>
<p>const options = {</p>
<p>          key: fs.readFileSync(&#39;privkey.pem&#39;),</p>
<p>          cert: fs.readFileSync(&#39;cert.pem&#39;)</p>
<p>};</p>
<p>const httpsServer = https.createServer(options);</p>
<p>httpsServer.listen(8080);</p>
<p>const io = require(&#39;socket.io&#39;)(httpsServer);</p>
<p>io.on(&#39;connection&#39;, function(socket) {</p>
<p>  socket.on(&#39;room&#39;, (room) =&gt; {</p>
<p>    console.log(&#34;Room: &#34;+room);</p>
<p>    socket.join(room);</p>
<p>  });</p>
<p>  socket.on(&#39;message&#39;, (msg) =&gt; {</p>
<p>    console.log(&#34;Message: &#34;+msg);</p>
<p>    socket.broadcast.emit(&#39;message&#39;, msg);</p>
<p>  });</p>
<p>});</p>
<h3><strong>Start Socket.io server</strong></h3>
<p>node server.js</p>
<pre>yarn start</pre>
<h3><strong>client.js</strong></h3>
<p>Connect to server and send the room message and after all further chat meesgages</p>
<p>// Strict mode changes previously accepted &#34;bad syntax&#34; into real errors.</p>
<p>&#39;use strict&#39;;</p>
<p>const room=&#34;testroom&#34;;</p>
<p>var log1 = document.querySelector(&#34;#textArea1&#34;);</p>
<p>var log2 = document.querySelector(&#34;#textArea2&#34;);</p>
<p>var input1 = document.querySelector(&#34;#input1&#34;);</p>
<p>var input2 = document.querySelector(&#34;#input2&#34;);</p>
<p>var signaling=new URL(window.location.href);</p>
<p>signaling.port = 8080;</p>
<p>signaling.pathname = &#39;/&#39;;</p>
<p>console.log(&#39;Signaling Server: &#39;+signaling);</p>
<p>var socket1 = io(signaling.href);</p>
<p>var socket2 = io(signaling.href);</p>
<p>socket1.on(&#39;connect&#39;, () =&gt;{</p>
<p>  console.log(&#34;Alice / socket1 ready&#34;);</p>
<p>  socket1.emit(&#39;room&#39;,room);</p>
<p>});</p>
<p>socket2.on(&#39;connect&#39;, () =&gt;{</p>
<p>  console.log(&#34;Bob / socket2 ready&#34;);</p>
<p>  socket2.emit(&#39;room&#39;,room);</p>
<p>});</p>
<p>socket1.on(&#39;message&#39;, msg =&gt;{</p>
<p>  log1.value += msg;</p>
<p>});</p>
<p>socket2.on(&#39;message&#39;, msg =&gt;{</p>
<p>  log2.value += msg;</p>
<p>});</p>
<p>input1.onkeypress = function (e){</p>
<p>  if (e.keyCode === 13 || e.which === 13) {</p>
<p>    var msg = &#34;Alice: &#34;+input1.value+&#34;\n&#34;;</p>
<p>    log1.value += msg;</p>
<p>    socket1.emit(&#39;message&#39;,msg);</p>
<p>    input1.value=&#34;&#34;;</p>
<p>  }</p>
<p>}</p>
<p>input2.onkeypress = function (e){</p>
<p>  if (e.keyCode === 13 || e.which === 13) {</p>
<p>    var msg = &#34;Bob: &#34;+input2.value+&#34;\n&#34;;</p>
<p>    log2.value += msg;</p>
<p>    socket2.emit(&#39;message&#39;,msg);</p>
<p>    input2.value=&#34;&#34;;</p>
<p>  }</p>
<p>}</p>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Set chat input to readonly by default, and remove readonly attribute only after room message already sent.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 8: Install KnockPlop" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Install a simple room based VC service</li>
<li>Combined mainly from the previous components.</li>
</ul>
<h2>Lab8</h2>
<p>KnockPlop is an Open Source basic multi participant peer-to-peer web multipart service based on WebRTC technology. Audio and Video conferencing with Screen Sharing Chat and Web Torrent based File Sharing. The service is based on videorooms, and simply connects everybody visiting the same URL. Private meetings based on random and long room id-s. It has a simple moodle integration. </p>
<h3><strong>Main Features</strong></h3>
<ul>
<li>Simple room based VideoConferencing</li>
<li>Mute Audio/Video</li>
<li>Screen Sharing</li>
<li>Chat</li>
<li>File Sharing</li>
<li>Moodle integration</li>
</ul>
<p><a href="https://github.com/so010/knockplop" target="_blank">https://github.com/so010/knockplop</a></p>
<h2><strong>Install</strong></h2>
<p>Checkout from git</p>
<pre>git clone https://github.com/so010/knockplop.git
cd knockplop
yarn</pre>
<h3><strong>Copy configs</strong></h3>
<pre>cp server-config.js.dist server-config.js
cp client-config.js.dist client-config.js</pre>
<h3><strong>Setup Certificate</strong></h3>
<p>Copy cert.pem and prikey.pem and Setup cert and key in <code>server-config.js</code></p>
<aside class="special"><p><strong>Tip</strong>:If you use the codelab vm and use let&#39;s encrypt cert, then use ../utils/certcopy.sh</p>
</aside>
<h3><strong>Setup TURN Server</strong></h3>
<aside class="warning"><p><strong>Warning!</strong> To access turn.geant.org <a href="https://technical.edugain.org/status" target="_blank">eduGAIN</a> access required!</p>
</aside>
<p>Go to <a href="https://turn.geant.org" target="_blank">https://turn.geant.org</a> to acquire credential to TURN service:</p>
<ol type="1" start="1">
<li>Setup REST key in <code>server-config.js</code> for Time Limited Long Term Credential. </li>
<li>Or Setup the old Long Term Credential = User/Password and configure the <code>client-config.js</code> according the credentials.</li>
</ol>
<h3><strong>Start Server</strong></h3>
<pre>yarn start</pre>
<aside class="warning"><p><strong>Warning!</strong> May you need to stop other server listening on port 80/443, or reconfigure port in <code>server-config.js</code></p>
</aside>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li><a href="https://demo.mediasoup.org/" target="_blank">https://demo.mediasoup.org/</a></li>
<li><a href="https://meet.jit.si/" target="_blank">https://meet.jit.si/</a></li>
<li><a href="https://janus.conf.meetecho.com/demos.html" target="_blank">https://janus.conf.meetecho.com/demos.html</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Congratulations" duration="5">
        <h2 class="checklist"><strong>What we&#39;ve covered</strong></h2>
<ul class="checklist">
<li>Grab your local WebCam Audio/Video Stream.</li>
<li>Get and Configure the Mediadevice supported parameters/constraints</li>
<li>Discover MediaDevices, specify Input/Output Mediadevice</li>
<li>Record localy a MediaStream using MediaRecorder API</li>
<li>Setup PeerConnection and howto follow it&#39;s states</li>
<li>Use DataChannel</li>
<li>Use a simple (socket.io based) Signaling Channel</li>
<li>Install KnockPlop</li>
</ul>
<h2><strong>Learn more about related API-s</strong></h2>
<p>GetUserMedia API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediacapture-streams/" target="_blank">https://www.w3.org/TR/mediacapture-streams/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia" target="_blank">developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia</a></li>
</ul>
<p>WebRTC API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/webrtc/" target="_blank">www.w3.org/TR/webrtc/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection" target="_blank">developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection</a></li>
</ul>
<p>WebAudio API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/webaudio/" target="_blank">www.w3.org/TR/webaudio/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" target="_blank">developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API</a></li>
</ul>
<p>MediaStream Recorder API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediastream-recording/" target="_blank">www.w3.org/TR/mediastream-recording/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/MediaRecorder" target="_blank">developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/MediaRecorder</a></li>
</ul>
<p>Media Capture from DOM Elements API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediacapture-fromelement/" target="_blank">www.w3.org/TR/mediacapture-fromelement/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasCaptureMediaStream" target="_blank">developer.mozilla.org/en-US/docs/Web/API/CanvasCaptureMediaStream</a></li>
</ul>
<p>Audio Output Devices API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/audio-output/" target="_blank">www.w3.org/TR/audio-output/</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Bonus: Debuging Browsers" duration="0">
        <h2><strong>Firefox:</strong></h2>
<h3><strong>about:webrtc</strong></h3>
<p>Open the URL above to see the under the hood informations about the MediaStreams and PeerConnections</p>
<h3><strong>Debug and Trace</strong></h3>
<pre>export NSPR_LOG_FILE=/home/ehugg/tmp/nspr.log
export NSPR_LOG_MODULES=signaling:5,mtransport:5,timestamp:1
export R_LOG_LEVEL=9
export R_LOG_DESTINATION=stderr</pre>
<h3><strong>ICE media log:</strong></h3>
<p>For ICE/STUN/TURN: </p>
<ul>
<li>Set R_LOG_DESTINATION=stderr </li>
<li>Set R_LOG_LEVEL=3 (can be anything between 1 and 9) </li>
<li>Set R_LOG_VERBOSE=1 if you want to include the module name generating the message </li>
</ul>
<p>For &#34;signaling&#34; (SDP offer/answer handling) and media transport, we use the normal Mozilla logging infrastructure, which uses a comma-separated list of modules, each one with its indicated log level; for WebRTC, you&#39;ll be most interested in these: </p>
<ul>
<li>Set NSPR_LOG_MODULES=signaling:5,mtransport:5 </li>
<li>You can also add &#34;,timestamp:1&#34; to that list if you want each log message to include timestamps. </li>
</ul>
<h2><strong>Debug Chrome</strong></h2>
<h3><strong>chrome://webrtc-internals</strong></h3>
<p>Open the URL above to see the under the hood informations about the MediaStreams and PeerConnections</p>
<h3><strong>Debug and Trace</strong></h3>
<pre>google-chrome --enable-logging=stderr --v=4 --vmodule=*libjingle/*=9 --vmodule=*media/*=9</pre>
<p><strong>linux log file</strong>: .config/chromium/chrome_debug.log</p>
<p>Basic info: <a href="https://www.chromium.org/for-testers/enable-logging" target="_blank">https://www.chromium.org/for-testers/enable-logging</a></p>
<ul>
<li>a) <code>--vmodule=*source*/talk/*=3</code></li>
<li>b)  <code>--vmodule=*third_party/libjingle/*=3</code></li>
<li>c) <code>--vmodule=*libjingle/source/talk/*=3</code></li>
</ul>
<p><code>--enable-logging=stderr --log-level=3 --vmodule=*libjingle/*=3,*=0</code></p>


      </google-codelab-step>
    
  </google-codelab>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-49880327-14', 'auto');

    (function() {
      var gaCodelab = '';
      if (gaCodelab) {
        ga('create', gaCodelab, 'auto', {name: 'codelab'});
      }

      var gaView;
      var parts = location.search.substring(1).split('&');
      for (var i = 0; i < parts.length; i++) {
        var param = parts[i].split('=');
        if (param[0] === 'viewga') {
          gaView = param[1];
          break;
        }
      }
      if (gaView && gaView !== gaCodelab) {
        ga('create', gaView, 'auto', {name: 'view'});
      }
    })();
  </script>

</body>
</html>
